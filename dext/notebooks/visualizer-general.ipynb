{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cf8e128",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from scipy import ndimage\n",
    "from matplotlib.patches import Ellipse, Rectangle\n",
    "import matplotlib.colors as pltc\n",
    "from dext.postprocessing.detection_visualization import get_text_origin\n",
    "import colorsys\n",
    "import random\n",
    "import alphashape\n",
    "from descartes import PolygonPatch\n",
    "\n",
    "SMALL_SIZE = 8\n",
    "MEDIUM_SIZE = 15\n",
    "BIGGER_SIZE = 20\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', size=MEDIUM_SIZE) # controls default text sizes\n",
    "plt.rc('axes', titlesize=MEDIUM_SIZE, labelsize=MEDIUM_SIZE, linewidth=2) # fontsize of the axes title\n",
    "plt.rc('xtick', labelsize=MEDIUM_SIZE) # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=MEDIUM_SIZE) # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=MEDIUM_SIZE) # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE) # fontsize of the figure title\n",
    "matplotlib.rcParams['text.latex.preamble'] = r'\\usepackage{sfmath} \\boldmath \\usepackage{bm} \\usepackage{amsmath}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46cd5b6e",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/dbscan_hp.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-c236270a58c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0msave_file_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'data/dbscan_hp.pkl'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_file_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mdbscan_hps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/dbscan_hp.pkl'"
     ]
    }
   ],
   "source": [
    "result_dir = '/media/deepan/externaldrive1/project_repos/DEXT_versions/dext/images/results/EFFICIENTDETD0_GuidedBackpropagation'\n",
    "\n",
    "saliency_image_paths = 'saliency_image_paths'\n",
    "\n",
    "ap_curve_linspace = 100\n",
    "\n",
    "coco_dataset_path = '/media/deepan/externaldrive1/datasets_project_repos/coco/remaining_val/'\n",
    "voc_dataset_path = '/media/deepan/externaldrive1/datasets_project_repos/voc/VOCdevkit/VOC2012/JPEGImages/'\n",
    "DATASET_PATH_USED = voc_dataset_path\n",
    "\n",
    "local_result_path_pattern_old = '/media/deepan/externaldrive1/project_repos/DEXT_versions/dext/images/results/'\n",
    "local_result_path_pattern_new = '/media/deepan/externaldrive1/project_repos/DEXT_versions/dext/images/results/'\n",
    "\n",
    "remote_result_path_pattern_old = '/scratch/dpadma2s/thesis/results/'\n",
    "remote_result_path_pattern_new = '/media/deepan/externaldrive1/project_repos/DEXT_versions/other_reports/'\n",
    "\n",
    "PATH_TO_REPLACE_OLD = local_result_path_pattern_old\n",
    "PATH_TO_REPLACE_NEW = local_result_path_pattern_new\n",
    "\n",
    "MODEL_NAME = 'EFFICIENTDETD0'\n",
    "INTERPRETATION_METHOD = 'GuidedBackpropagation'\n",
    "IMAGE_INDEX = '2010_005511'\n",
    "FILENAME_TO_SAVE = 'data/'+ IMAGE_INDEX + '_' + MODEL_NAME + '.jpg'\n",
    "\n",
    "\n",
    "save_file_name = 'data/dbscan_hp.pkl'\n",
    "with open(save_file_name, 'rb') as f:\n",
    "    dbscan_hps = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e38e3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_history_file(result_dir, filename):\n",
    "    if os.path.exists(result_dir):\n",
    "        file = os.path.join(result_dir, filename)\n",
    "        if os.path.exists(file):\n",
    "            return file\n",
    "        else:\n",
    "            raise ValueError('File in directory unavailable') \n",
    "    else:\n",
    "        raise ValueError('Result directory unavailable')\n",
    "\n",
    "def get_image_index_counts(result_dir, filename):\n",
    "    file = get_history_file(result_dir, filename)\n",
    "    data = [json.loads(line) for line in open(file, 'r')]\n",
    "    data = np.array(data)\n",
    "    all_image_index = list(np.unique(data[:, 0]))\n",
    "    return len(all_image_index)\n",
    "\n",
    "def get_data(result_dir, filename):\n",
    "    model_name_interpretation = (result_dir.split('/')[-1])\n",
    "    model_name = model_name_interpretation.split('_')[0]\n",
    "    interpretation_method = model_name_interpretation.split('_')[1]\n",
    "    print('Model name: %s | Interpretation method: %s' % (model_name, interpretation_method))\n",
    "    print(\"Number of saliency image paths: \", get_image_index_counts(result_dir, saliency_image_paths))\n",
    "    file = get_history_file(result_dir, filename)\n",
    "    data = [json.loads(line) for line in open(file, 'r')]\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed81dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(filepath):\n",
    "    print(\"Reading image file: \", filepath)\n",
    "    raw_image = cv2.imread(filepath)\n",
    "    raw_image = cv2.cvtColor(raw_image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(raw_image, (512, 512))\n",
    "    return raw_image, image\n",
    "\n",
    "def clean_data(data, file_path_avail, file_path_replacement):\n",
    "    for i in data:\n",
    "        temp = i[-2]\n",
    "        temp = temp.replace(file_path_avail, file_path_replacement)\n",
    "        i[-2] = temp\n",
    "    return data\n",
    "\n",
    "def rescale_box(box, old_size, new_size):\n",
    "    image_h, image_w, _ = old_size\n",
    "    new_h, new_w = new_size\n",
    "    x_min, y_min, x_max, y_max = box\n",
    "    x_min = max(0, int((x_min / image_w) * new_w))\n",
    "    y_min = max(0, int((y_min / image_h) * new_h))\n",
    "    x_max = min(int((x_max / image_w) * new_w), new_w)\n",
    "    y_max = min(int((y_max / image_h) * new_h), new_h)\n",
    "    return x_min, y_min, x_max, y_max\n",
    "\n",
    "def plot_bbox(box, edge_color, ax):\n",
    "    if not ax:\n",
    "        fig = plt.figure(frameon=False)\n",
    "        ax = fig.add_subplot()\n",
    "    x_min, y_min, x_max, y_max = box     \n",
    "    rect = Rectangle((x_min, y_min), (x_max - x_min), (y_max - y_min), linewidth=1, edgecolor=edge_color,\n",
    "                    facecolor='none', alpha=0.7)\n",
    "    ax.add_patch(rect)\n",
    "    \n",
    "def plot_text(text, box, edge_color, ax, fontsize=12):\n",
    "    props = dict(edgecolor='none', facecolor='none', boxstyle='square')   \n",
    "    ax.text(box[0], box[3]-10, text, color='white', bbox=props, fontsize=fontsize, clip_on=True, wrap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1efb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_heatmaps(data, model_name):\n",
    "    class_maps = []\n",
    "    box_maps1 = []\n",
    "    box_maps2 = []\n",
    "    box_maps3 = []\n",
    "    box_maps4 = []\n",
    "    class_maps_boxes = []\n",
    "    box_maps1_boxes = []\n",
    "    box_maps2_boxes = []\n",
    "    box_maps3_boxes = []\n",
    "    box_maps4_boxes = []\n",
    "    labels = []\n",
    "    for i in data:\n",
    "        if i[5] == 'Classification':\n",
    "            class_maps.append(np.load(i[-2]))\n",
    "            class_maps_boxes.append(i[2])\n",
    "            labels.append(i[4])\n",
    "        elif i[5] == 'Boxoffset' and i[6] == 0:\n",
    "            box_maps1.append(np.load(i[-2]))\n",
    "            box_maps1_boxes.append(i[2])\n",
    "        elif i[5] == 'Boxoffset' and i[6] == 1:\n",
    "            box_maps2.append(np.load(i[-2]))\n",
    "            box_maps2_boxes.append(i[2])\n",
    "        elif i[5] == 'Boxoffset' and i[6] == 2:\n",
    "            box_maps3.append(np.load(i[-2]))\n",
    "            box_maps3_boxes.append(i[2])\n",
    "        elif i[5] == 'Boxoffset' and i[6] == 3:\n",
    "            box_maps4.append(np.load(i[-2]))\n",
    "            box_maps4_boxes.append(i[2])\n",
    "        else:\n",
    "            raise ValueError('Unknown explaining flag')\n",
    "    data = {}        \n",
    "    data['class_maps'] = class_maps\n",
    "    data['class_maps_boxes'] = class_maps_boxes\n",
    "    data['box_maps1'] = box_maps1\n",
    "    data['box_maps1_boxes'] = box_maps1_boxes\n",
    "    data['box_maps2'] = box_maps2\n",
    "    data['box_maps2_boxes'] = box_maps2_boxes\n",
    "    data['box_maps3'] = box_maps3\n",
    "    data['box_maps3_boxes'] = box_maps3_boxes\n",
    "    data['box_maps4'] = box_maps4\n",
    "    data['box_maps4_boxes'] = box_maps4_boxes\n",
    "    data['labels'] = labels\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66877e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "fasterrcnn_data = get_data(result_dir, saliency_image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fbd02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find unique image ids\n",
    "column_names = ['image_index', 'object_index', 'box', 'confidence', 'class', 'explaining',\n",
    "                'boxoffset', 'saliency_path', 'image_path']\n",
    "count_image_index = np.unique(\n",
    "    fasterrcnn_data[:, column_names.index('image_index')], return_counts=True)\n",
    "count_image_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081a5c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select image index to draw images\n",
    "fasterrcnn_ex1_data = fasterrcnn_data[\n",
    "    fasterrcnn_data[:,column_names.index('image_index')] == IMAGE_INDEX]\n",
    "fasterrcnn_ex1_data = clean_data(\n",
    "    fasterrcnn_ex1_data, PATH_TO_REPLACE_OLD, PATH_TO_REPLACE_NEW)\n",
    "fasterrcnn_ex1_image = read_image(\n",
    "    filepath=os.path.join(DATASET_PATH_USED, \n",
    "                          fasterrcnn_ex1_data[0][-1].split('/')[-1]))   \n",
    "fasterrcnn_ex1_map_dict = get_heatmaps(fasterrcnn_ex1_data, MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d72a89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weighted_average(img):\n",
    "    y = range(0, img.shape[0])\n",
    "    x = range(0, img.shape[1])\n",
    "    Y, X = np.meshgrid(y,x)\n",
    "    y_coord = (Y*img).sum() / img.sum().astype(\"float\")\n",
    "    x_coord = (X*img).sum() / img.sum().astype(\"float\")\n",
    "    return np.array([x_coord, y_coord])\n",
    "\n",
    "def calculate_covariance(ex_map):\n",
    "    y = range(0, ex_map.shape[0])\n",
    "    x = range(0, ex_map.shape[1])\n",
    "    Y, X = np.meshgrid(y,x)\n",
    "    X = X.flatten()\n",
    "    Y = Y.flatten()\n",
    "    value = np.vstack((X, Y))\n",
    "    weight = ex_map.flatten()\n",
    "    cov = np.cov(value, aweights=weight)\n",
    "    return cov\n",
    "\n",
    "def find_eigens(cov):\n",
    "    eigvals, eigvecs = np.linalg.eigh(cov)\n",
    "    order = eigvals.argsort()[::-1]\n",
    "    eigvals, eigvecs = eigvals[order], eigvecs[:, order]\n",
    "    return eigvals, eigvecs\n",
    "\n",
    "\n",
    "\n",
    "def get_matplotlib_colors(num_colors):\n",
    "    color = [k for k,v in pltc.cnames.items()]\n",
    "    random.seed(45)\n",
    "    random.shuffle(color)\n",
    "    jump_col = np.floor(len(color) / num_colors)\n",
    "    filtered = [i for n,i in enumerate(color) if (n%jump_col==0)]\n",
    "    return filtered\n",
    "\n",
    "def plot_explanation_ellipse(image, ex_map, edge_color='blue', ax=None, levels=1):\n",
    "    if not ax:\n",
    "        fig = plt.figure(frameon=False)\n",
    "        ax = fig.add_subplot()\n",
    "    centroid = ndimage.measurements.center_of_mass(ex_map)\n",
    "    origin = [centroid[1], centroid[0]]\n",
    "    \n",
    "    eigvals, eigvecs = find_eigens(calculate_covariance(ex_map))\n",
    "    vx, vy = eigvecs[:, 0][0], eigvecs[:, 0][1]\n",
    "    theta = np.arctan2(vy, vx)\n",
    "    width, height = np.sqrt(eigvals)\n",
    "    for nsig in range(1, levels+1):\n",
    "        e = Ellipse(xy=origin, width=nsig*width, height=nsig*height, angle=np.degrees(theta), \n",
    "                    color=edge_color, fill=None, linewidth=1, alpha=0.7)\n",
    "        e.set_clip_box(ax.bbox)\n",
    "        ax.add_patch(e)\n",
    "    #plt.quiver(*origin, *eigvecs[0,:], color=edge_color, scale=15)\n",
    "    #plt.quiver(*origin, *eigvecs[:, 1], color=edge_color, scale=15)\n",
    "    ax.imshow(image)\n",
    "    \n",
    "def plot_bbox(box, edge_color, ax):\n",
    "    if not ax:\n",
    "        fig = plt.figure(frameon=False)\n",
    "        ax = fig.add_subplot()\n",
    "    x_min, y_min, x_max, y_max = box     \n",
    "    rect = Rectangle((x_min, y_min), (x_max - x_min), (y_max - y_min), linewidth=1, edgecolor=edge_color,\n",
    "                    facecolor='none', alpha=0.7)\n",
    "    ax.add_patch(rect)\n",
    "    \n",
    "def plot_text(text, box, color, ax, fontsize=12):\n",
    "    props = dict(edgecolor='none', facecolor='none', boxstyle='square')   \n",
    "    xmin, ymin, xmax, ymax = box\n",
    "    if xmin <= 0:\n",
    "        text_x = 1\n",
    "    else:\n",
    "        text_x = xmin\n",
    "    if ymin <= 15:\n",
    "        text_y = ymax + 19\n",
    "    else:\n",
    "        text_y = ymin - 8\n",
    "    ax.text(text_x, text_y, text, color=color, bbox=props, \n",
    "            fontsize=fontsize, clip_on=True, wrap=True, weight='bold')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b83dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.transform\n",
    "from distutils.version import LooseVersion\n",
    "\n",
    "def resize(image, output_shape, order=1, mode='constant', cval=0, clip=True,\n",
    "           preserve_range=False, anti_aliasing=False,\n",
    "           anti_aliasing_sigma=None):\n",
    "    \"\"\"A wrapper for Scikit-Image resize().\n",
    "\n",
    "    Scikit-Image generates warnings on every call to resize() if it doesn't\n",
    "    receive the right parameters. The right parameters depend on the version\n",
    "    of skimage. This solves the problem by using different parameters per\n",
    "    version. And it provides a central place to control resizing defaults.\n",
    "    \"\"\"\n",
    "    if LooseVersion(skimage.__version__) >= LooseVersion(\"0.14\"):\n",
    "        # New in 0.14: anti_aliasing. Default it to False for backward\n",
    "        # compatibility with skimage 0.13.\n",
    "        return skimage.transform.resize(\n",
    "            image, output_shape,\n",
    "            order=order, mode=mode, cval=cval, clip=clip,\n",
    "            preserve_range=preserve_range, anti_aliasing=anti_aliasing,\n",
    "            anti_aliasing_sigma=anti_aliasing_sigma)\n",
    "    else:\n",
    "        return skimage.transform.resize(\n",
    "            image, output_shape,\n",
    "            order=order, mode=mode, cval=cval, clip=clip,\n",
    "            preserve_range=preserve_range)\n",
    "\n",
    "def resize_image_fasterrcnn(image, min_dim=512, max_dim=512, min_scale=0, mode=\"square\"):\n",
    "    \"\"\"Resizes an image keeping the aspect ratio unchanged.\n",
    "\n",
    "    # Arguments:\n",
    "        min_dim: Minimum dimension of image to resize\n",
    "        max_dim: Maximum dimension of image to resize\n",
    "        min_scale: Image scale percentage\n",
    "        mode: Resizing mode. e.g. None, square, pad64 or crop\n",
    "\n",
    "    # Returns:\n",
    "        image: Resized image\n",
    "        window: Coordinates of unpadded image (y_min, x_min, y_max, x_max)\n",
    "        padding: Padding added to the image\n",
    "            [(top, bottom), (left, right), (0, 0)]\n",
    "    \"\"\"\n",
    "    image_dtype = image.dtype\n",
    "    H, W = image.shape[:2]\n",
    "    window = (0, 0, H, W)\n",
    "    scale = 1\n",
    "    padding = [(0, 0), (0, 0), (0, 0)]\n",
    "    crop = None\n",
    "\n",
    "    if mode == 'none':\n",
    "        return image, window, scale, padding, crop\n",
    "\n",
    "    if min_dim:\n",
    "        scale = max(1, min_dim / min(H, W))\n",
    "    if min_scale and scale < min_scale:\n",
    "        scale = min_scale\n",
    "\n",
    "    if max_dim and mode == 'square':\n",
    "        image_max = max(H, W)\n",
    "        if round(image_max * scale) > max_dim:\n",
    "            scale = max_dim / image_max\n",
    "    if scale != 1:\n",
    "        image = resize(image, (round(H * scale), round(W * scale)),\n",
    "                       preserve_range=True)\n",
    "    H, W = image.shape[:2]\n",
    "    top_pad = (max_dim - H) // 2\n",
    "    bottom_pad = max_dim - H - top_pad\n",
    "    left_pad = (max_dim - W) // 2\n",
    "    right_pad = max_dim - W - left_pad\n",
    "    padding = [(top_pad, bottom_pad), (left_pad, right_pad), (0, 0)]\n",
    "    image = np.pad(image, padding, mode='constant', constant_values=0)\n",
    "    window = (top_pad, left_pad, H + top_pad, W + left_pad)\n",
    "    return image.astype(image_dtype), window, scale, padding, crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354e710f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(raw_image, image_size, model_name):\n",
    "    if model_name == 'FasterRCNN':\n",
    "        image,  window, _, _, _ = resize_image_fasterrcnn(raw_image, image_size[0], image_size[1])\n",
    "    else:\n",
    "        image = cv2.resize(raw_image, image_size)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406f9aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap = fasterrcnn_ex1_map_dict['class_maps'][3]\n",
    "plt.imshow(heatmap, cmap='inferno')\n",
    "plt.imshow(fasterrcnn_ex1_image[1], alpha=0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c29459",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from scipy.spatial import ConvexHull, convex_hull_plot_2d\n",
    "\n",
    "def plot_points(points, color, ax):\n",
    "    ax.plot(points[:, 1], points[:, 0], '+', markerfacecolor=color, \n",
    "            markeredgecolor=color, markersize=2)\n",
    "    \n",
    "    \n",
    "def draw_contours(points, color, ax, plot_convex=False):\n",
    "    if plot_convex:\n",
    "        hull = ConvexHull(points)\n",
    "        for simplex in hull.simplices:\n",
    "            plt.plot(points[simplex, 1], points[simplex, 0], color)\n",
    "        ax.plot(points[hull.vertices, 1], points[hull.vertices, 0], color)\n",
    "        ax.plot(points[hull.vertices[0], 1], points[hull.vertices[0], 0], color)\n",
    "    else:\n",
    "        # https://alphashape.readthedocs.io/en/latest/readme.html\n",
    "        points = [(x, y) for y,x in points]\n",
    "        alpha = 0.1\n",
    "        hull = alphashape.alphashape(points, alpha)\n",
    "        ax.add_patch(PolygonPatch(hull, fill=False, color=color))\n",
    "    \n",
    "\n",
    "def find_biggest_cluster(cluster_label_points):\n",
    "    max_points_cluster_id = None\n",
    "    max_points = 0\n",
    "    for label, points in cluster_label_points.items():\n",
    "        num_points = len(points)\n",
    "        if num_points >= max_points:\n",
    "            max_points_cluster_id = label\n",
    "            max_points = num_points\n",
    "    filtered_cluster = cluster_label_points[max_points_cluster_id]\n",
    "    return filtered_cluster\n",
    "\n",
    "\n",
    "def plot_dbscan_cluster(cluster_label_points, color=None, ax=None, clean_points=False):\n",
    "    if not color:\n",
    "        color = 'red'\n",
    "    if not ax:\n",
    "        fig = plt.figure(frameon=False)\n",
    "        ax = fig.add_subplot()\n",
    "    cluster_ids = list(cluster_label_points.keys())\n",
    "    if len(cluster_ids) == 1 and -1 in cluster_ids:\n",
    "        print('No clusters found by DBSCAN')\n",
    "    else:\n",
    "        if clean_points:\n",
    "            filtered_cluster = find_biggest_cluster(cluster_label_points)\n",
    "            plot_points(filtered_cluster, color, ax)\n",
    "#             draw_contours(filtered_cluster, color, ax)\n",
    "        else:\n",
    "            for label, points in cluster_label_points.items():\n",
    "                if label == -1:\n",
    "                    continue\n",
    "                plot_points(points, color, ax)\n",
    "#                 draw_contours(points, color, ax)\n",
    "\n",
    "                \n",
    "def dbscan_cluster(heatmap, eps, min_points):\n",
    "    # convert to black and white\n",
    "    gray = np.uint8(heatmap * 255)\n",
    "    # 204 because taking 0.8 <\n",
    "    (thresh, blackAndWhiteImage) = cv2.threshold(gray, 204, 255, cv2.THRESH_BINARY)\n",
    "    blackAndWhiteImage = cv2.bitwise_not(blackAndWhiteImage)\n",
    "    # convert black pixels to coordinates\n",
    "    X = np.column_stack(np.where(blackAndWhiteImage == 0))\n",
    "    # Compute DBSCAN\n",
    "    db = DBSCAN(eps=eps, min_samples=min_points).fit(X)\n",
    "    core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "    core_samples_mask[db.core_sample_indices_] = True\n",
    "    labels = db.labels_\n",
    "    # Number of clusters in labels, ignoring noise if present.\n",
    "    n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    n_noise_ = list(labels).count(-1)\n",
    "    print('Estimated number of clusters: %d' % n_clusters_)\n",
    "    print('Estimated number of noise points: %d' % n_noise_)\n",
    "    unique_labels = set(labels)\n",
    "    cluster_label_points = dict()\n",
    "    for label in unique_labels:\n",
    "        class_member_mask = (labels == label)\n",
    "        xy = X[class_member_mask & core_samples_mask]\n",
    "        cluster_label_points[label] = xy\n",
    "    return cluster_label_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5366133",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eps(class_name, model_method):\n",
    "    eps = None\n",
    "    for i in dbscan_hps:\n",
    "        if i['name'] == model_method:\n",
    "            idx = i['classes'].index(class_name)\n",
    "            eps = i['eps'][idx]\n",
    "    if eps:\n",
    "        return eps\n",
    "    else:\n",
    "        eps = [50, 50, 50, 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddfc996",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "raw_image = cv2.imread(os.path.join(DATASET_PATH_USED, IMAGE_INDEX +'.jpg'))\n",
    "raw_image = cv2.cvtColor(raw_image, cv2.COLOR_BGR2RGB)\n",
    "image = resize_image(raw_image, (512, 512), 'None')\n",
    "image_overlay = resize_image(raw_image, (512, 512), 'FasterRCNN')\n",
    "\n",
    "fig = plt.figure(frameon=False, num=1, clear=True)\n",
    "ax = fig.add_subplot()\n",
    "ax.set_axis_off()\n",
    "\n",
    "colors = get_matplotlib_colors(len(fasterrcnn_ex1_map_dict['class_maps']))\n",
    "num_maps = len(fasterrcnn_ex1_map_dict['class_maps'])\n",
    "for i in range(num_maps):\n",
    "    edge_color = colors[i]\n",
    "    label = fasterrcnn_ex1_map_dict['labels'][i]\n",
    "    model_method = MODEL_NAME + '_' + INTERPRETATION_METHOD\n",
    "    eps = get_eps(label, model_method)\n",
    "    print('DBSCAN-ing high-level visual explanation for object: ', label, eps)\n",
    "    min_points = 50\n",
    "    eps = eps[2]\n",
    "    box = rescale_box(fasterrcnn_ex1_map_dict['class_maps_boxes'][i], raw_image.shape, \n",
    "                      fasterrcnn_ex1_map_dict['class_maps'][i].shape)\n",
    "    plot_bbox(box, edge_color, ax)\n",
    "    heatmap = fasterrcnn_ex1_map_dict['class_maps'][i]\n",
    "    cluster_label_points = dbscan_cluster(heatmap, eps, min_points)\n",
    "    plot_dbscan_cluster(cluster_label_points, edge_color, ax)\n",
    "    plt.imshow(fasterrcnn_ex1_image[1])\n",
    "    plot_text(fasterrcnn_ex1_map_dict['labels'][i], box, edge_color, ax)\n",
    "\n",
    "fig.savefig(FILENAME_TO_SAVE, dpi=300, bbox_inches='tight', pad_inches=0)\n",
    "plt.show()\n",
    "fig.clear()\n",
    "plt.close(fig)\n",
    "fig.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57d7465",
   "metadata": {},
   "outputs": [],
   "source": [
    "mock = fasterrcnn_ex1_map_dict['class_maps'][0]\n",
    "gray = np.uint8(mock * 255)\n",
    "# 204 because taking 0.8 <\n",
    "(thresh, blackAndWhiteImage) = cv2.threshold(gray, 204, 255, cv2.THRESH_BINARY)\n",
    "blackAndWhiteImage = cv2.bitwise_not(blackAndWhiteImage)\n",
    "# convert black pixels to coordinates\n",
    "X = np.column_stack(np.where(blackAndWhiteImage == 0))\n",
    "\n",
    "import kneed\n",
    "from kneed import KneeLocator\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "minpoints = 100\n",
    "neighbors = minpoints - 1\n",
    "# Nearest neighbors\n",
    "nbrs = NearestNeighbors(n_neighbors=neighbors).fit(X)\n",
    "distances, indices = nbrs.kneighbors(X)\n",
    "distance_desc = sorted(distances[:,neighbors-1], reverse=True)\n",
    "fig, ax = plt.subplots(figsize=(7, 4))\n",
    "ax.plot(distance_desc)\n",
    "ax.set_ylabel('distances')\n",
    "ax.set_xlabel('points')\n",
    "ax.grid()\n",
    "plt.show()\n",
    "print(len(X), len(distance_desc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d1f7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "kneedle = KneeLocator(range(1,len(distance_desc)+1),  #x values\n",
    "                      distance_desc, # y values\n",
    "                      S=1.0, #parameter suggested from paper\n",
    "                      curve=\"convex\", #parameter from figure\n",
    "                      direction=\"decreasing\") #parameter from figure\n",
    "kneedle.plot_knee()\n",
    "min_points = kneedle.elbow \n",
    "eps = kneedle.knee_y\n",
    "plt.grid()\n",
    "print('eps: ', eps)\n",
    "print('min points: ', min_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc98e79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685e004c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paz_efficientdet",
   "language": "python",
   "name": "paz_efficientdet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
